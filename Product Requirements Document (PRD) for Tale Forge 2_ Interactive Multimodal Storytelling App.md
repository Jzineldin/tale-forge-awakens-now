# Product Requirements Document (PRD) for Tale Forge 2: Interactive Multimodal Storytelling App

## 1. Introduction

### 1.1 Purpose

This Product Requirements Document (PRD) outlines the features, functionalities, and technical requirements for Tale Forge 2, an interactive multimodal storytelling application. The purpose of this document is to provide a clear and comprehensive guide for the development team, ensuring a shared understanding of the product vision, target audience, and implementation details. It aims to facilitate the development process, clarify expectations, and serve as a foundational reference for all stakeholders involved in the project.

### 1.2 Product Overview

Tale Forge 2 is an innovative AI-powered platform that redefines interactive storytelling. It allows users to craft unique, branching narratives where their choices dynamically influence the story's progression. Beyond traditional text-based adventures, Tale Forge 2 integrates AI-generated images for each story segment and, crucially, generates voiceovers in the background. The ultimate vision for the application is to compile these generated images and voices into a dynamic, animated video upon story completion, offering an immersive and shareable experience. The application leverages multiple advanced AI systems, including Google Gemini for narrative generation, OpenAI DALL-E for image creation, ElevenLabs for text-to-speech, and Pollo AI for image-to-video animation.

### 1.3 Target Audience

The primary target audience for Tale Forge 2 is **Creative Explorers & AI Enthusiasts**. These individuals are typically 16-45 years old, possess high tech savviness, and are deeply interested in interactive fiction, generative AI, digital art, and personalized entertainment. They are curious, experimental, value personalization, and seek immersive experiences that push the boundaries of digital media. They appreciate the cutting-edge integration of AI and are motivated by the creative potential it offers.

A secondary target audience includes **Educators & Creative Writers**. This group, ranging broadly in age, uses digital tools regularly and is interested in innovative teaching methods, creative writing prompts, and leveraging technology for educational or artistic purposes. They seek tools to inspire creativity, overcome writer's block, or create engaging interactive content.

This focused targeting ensures that the application's unique AI-driven and multimodal capabilities resonate with users who will most appreciate and utilize its advanced features, while also opening avenues for broader adoption in creative and educational fields.

### 1.4 Scope

This PRD covers the core interactive storytelling experience, the integration of AI-generated multimodal assets (images and audio), the planned premium animated video compilation feature, and key user experience enhancements. It details both frontend and backend requirements necessary to achieve the product vision. The document also addresses improvements identified through user feedback and testing, aiming to refine existing functionalities and introduce new ones that enhance user engagement and satisfaction.

## 2. Features

### 2.1 Core Interactive Storytelling

**Description:** The fundamental functionality of Tale Forge 2 revolves around a branching narrative system where users make choices that influence the story's direction. The narrative is dynamically generated by AI, providing a unique experience with each playthrough.

**Requirements:**
*   **AI-Powered Narrative Generation:** The application must utilize Google Gemini (or OpenAI GPT-4o as an alternative) to generate coherent, engaging, and contextually relevant story segments (120-150 words per segment).
*   **Choice Generation:** For each story segment, the AI must generate 2-3 distinct and meaningful choices that allow users to influence the narrative path.
*   **Narrative Consistency:** The AI system must maintain narrative and visual context across all segments, ensuring character consistency, plot coherence, and genre adherence (e.g., Horror, Epic Fantasy, Sci-Fi Thriller).
*   **Story Mode Selection:** Users must be able to select from a variety of predefined story modes (genres) on the home page, which will guide the AI's generation style.
*   **Custom Story Prompts:** Users should have the option to input their own custom starting prompts to initiate a story.

### 2.2 Multimodal Asset Generation (Background)

**Description:** To enhance immersion and provide a rich storytelling experience, Tale Forge 2 generates visual and auditory assets for each story segment in the background, without interrupting the user's interactive reading flow.

**Requirements:**
*   **Background Image Generation (DALL-E 3):**
    *   For each generated story segment, the AI (Gemini/GPT-4o) must also generate a concise, descriptive image prompt.
    *   This image prompt will be sent to OpenAI DALL-E 3 (leveraging the user's ChatGPT Premium access) to generate a contextually relevant image.
    *   Image generation must occur asynchronously in the background. The user should receive the text segment and choices immediately, with the image appearing once ready.
    *   Generated images (or their URLs) must be stored and associated with their respective story segments for later video compilation.
    *   **Fallback System:** In case of DALL-E 3 generation failure or timeout, a curated Unsplash image or a generic placeholder should be displayed.
*   **Background Voice Generation (ElevenLabs):**
    *   For each generated story segment, the text will be sent to ElevenLabs for high-quality, natural-sounding voiceover generation.
    *   Voice generation must occur asynchronously in the background.
    *   Generated audio files (MP3/WAV) must be stored and associated with their respective story segments.
    *   The exact duration of each audio segment must be recorded for precise video synchronization.

### 2.3 Premium Animated Video Compilation

**Description:** Upon the user's completion of a story, all generated images and voiceovers will be compiled into a dynamic, animated video, offering a shareable and immersive final product. This is a premium feature.

**Requirements:**
*   **Trigger:** A "Create Animated Video" button will be available at the end of a completed story.
*   **Image-to-Video Animation (Pollo AI Integration):**
    *   For each static image generated by DALL-E 3, Pollo AI will be used to transform it into a short, animated video clip.
    *   **API Endpoint:** `https://api.pollo.ai/v1/video/generate`
    *   **Method:** POST
    *   **Authentication:** API Key (`X-API-KEY`) in the header.
    *   **Request Body:** `model` (e.g., `pollo-ai/pollo-1.6`), `input_type` (`image_to_video`), `image_url` (URL of the static image), `prompt` (text prompt for animation, e.g., "a subtle camera pan"), `output_format` (`mp4`).
    *   **Asynchronous Processing:** The call to Pollo AI must be asynchronous, returning a `task_id`.
    *   **Status Polling:** The system must poll `https://api.pollo.ai/v1/video/status` using the `task_id` until the video generation is `succeed`.
    *   **Temporary Storage:** The URLs of the generated animated video clips must be temporarily stored.
*   **Final Video Compilation (FFmpeg/Server-side Tool):**
    *   Once all animated video clips from Pollo AI and their corresponding ElevenLabs TTS audio files are ready, they will be combined into a single MP4 video.
    *   **Synchronization:** Each animated video clip must be synchronized with its matching TTS audio, playing for the exact duration of the audio segment.
    *   **Transitions:** Smooth transitions between video segments should be implemented.
    *   **Concatenation:** All segments will be stitched together into one final MP4 video file.
    *   **Delivery:** The completed MP4 video file will be stored, and the user will be provided with a link to view or download it.

### 2.4 User Experience (UX) Enhancements

**Description:** Improvements to core UX flows based on user feedback to enhance usability and satisfaction.

**Requirements:**
*   **Refined Story Conclusion:**
    *   When the user selects "Finish Story Here," the AI (Google Gemini/OpenAI GPT-4o) must generate a concise and satisfying narrative conclusion to the current story arc, providing a sense of closure.
    *   The prompt to the AI should clearly indicate the need for a final, concluding segment.
*   **Single Audio Player:**
    *   The frontend UI must be reviewed and modified to ensure that only a single audio player instance is displayed per story segment or page, eliminating duplicate players.
*   **Improved "My Stories" Section:**
    *   **Visual Overhaul:** Implement a more visually appealing and organized layout for "My Stories," such as a grid view or card-based design, displaying story title, status, and creation date prominently.
    *   **Pagination/Infinite Scroll:** Implement pagination or infinite scrolling for efficient loading and navigation of a large number of stories.
    *   **Filtering and Sorting:** Provide clear options to filter stories by status ("In Progress," "Completed") and sort by creation date, title, or last modified date.
    *   **"Continue Story" Option:** For stories marked as "Completed," an explicit "Continue Story" button/action must be available. This action should reload the story from its last saved state, allowing users to resume or explore alternative paths.
    *   **Story State Storage:** The backend must store the full story state (including all previous segments and choices) for each story to enable the "Continue Story" functionality.
    *   **"Edit/Rename" Option:** Users should be able to rename their saved stories.
    *   **"Delete" Option:** A clear and confirmable delete option for stories must be provided.
    *   **Visual Cues:** Use distinct visual cues (icons, colors) to differentiate story statuses.

## 3. Technical Architecture

### 3.1 Frontend (React/TypeScript)

**Description:** The user-facing application built with modern web technologies to provide a responsive and intuitive interface.

**Components:**
*   `StoryPage.tsx`: Main interface for interactive storytelling, displaying text, image, choices, and audio controls.
*   `Auth Components`: For user sign-in/sign-up.
*   `MyStoriesPage.tsx`: Displays user's saved stories with enhanced management features.
*   `PublicStoriesPage.tsx`: For community sharing features.

**Technologies:**
*   React/TypeScript: For building robust and scalable UI.
*   React Query: For efficient API calls and state management.
*   Supabase Real-time Subscriptions: For live updates of story content.
*   Tailwind CSS + Shadcn/UI: For styling and UI components.
*   React Router: For navigation and protected routes.

**Key Considerations:**
*   **Asynchronous UI Updates:** Ensure that image and audio generation, and video compilation, do not block the main UI thread. Implement loading indicators and graceful fallback mechanisms.
*   **Responsive Design:** The application must be fully responsive and provide an optimal experience across various devices (desktop, tablet, mobile).

### 3.2 Backend (Supabase Edge Functions)

**Description:** Serverless functions hosted on Supabase to handle AI integrations, data processing, and asset management.

**Key Functions/Endpoints:**
*   `generate-story-segment`: Orchestrates AI calls for text generation (Gemini/GPT-4o), image prompt generation, and initiates background image generation.
*   `generate-image` (New/Modified): Handles the DALL-E 3 API calls, image storage (Supabase storage), and returns image URLs.
*   `generate-audio` (New/Modified): Handles ElevenLabs TTS API calls, audio storage, and returns audio URLs and durations.
*   `animate-story-segment` (New): Handles Pollo AI image-to-video API calls, status polling, and temporary storage of animated clips.
*   `compile-final-video` (New): Orchestrates the final video compilation using FFmpeg or a similar server-side video processing tool, combining animated clips and audio.
*   **Story Management Endpoints:** For saving, retrieving, updating, and deleting stories and their segments.

**Technologies:**
*   Supabase Edge Functions: For serverless backend logic.
*   Supabase Database: For storing story metadata, segments, user data, and admin settings.
*   Supabase Storage: For storing generated images and audio files.
*   FFmpeg (Server-side): For video compilation (if available/integrated).

**Key Considerations:**
*   **API Key Management:** Securely store all API keys (OpenAI, ElevenLabs, Pollo AI) as environment variables or secrets.
*   **Error Handling & Fallbacks:** Implement robust error handling for all external API calls (retries, graceful degradation, fallback images).
*   **Scalability:** Design functions to handle concurrent requests efficiently.
*   **Asynchronous Processing:** Critical for all AI generation and video compilation tasks to ensure a smooth user experience.

### 3.3 Database Architecture (Supabase)

**Description:** The data model for storing all application-related information.

**Core Tables:**
*   `stories`: Stores metadata for each story (user ID, title, genre, completion status, thumbnail, creation/last modified dates).
*   `story_segments`: Stores individual segments of a story, including text, image URL, audio URL, choices, and parent-child relationships for branching.
*   `admin_settings`: System configuration (AI model preferences, cost controls, feature toggles).
*   `user_roles`: For user management and permissions.

**Advanced Features:**
*   **Real-time Updates:** Supabase real-time subscriptions for live updates.
*   **Row Level Security (RLS):** Ensure users can only access their own stories.
*   **Branching Structure:** Maintain parent-child relationships between segments to support complex narratives and the "Continue Story" feature.

## 4. Metrics & Analytics

**Description:** Key metrics to track product performance, user engagement, and AI efficiency.

**Key Metrics:**
*   **User Engagement:** Number of active users, stories started, stories completed, average session duration, choices made per story.
*   **Feature Usage:** Adoption rate of premium video generation, usage of "Continue Story" feature, genre popularity.
*   **AI Performance:** Latency of AI responses (text, image, audio generation), success rate of AI calls, quality of generated content (qualitative assessment).
*   **Cost Efficiency:** API costs per story, cost per image/audio/video generation.

## 5. Future Considerations

**Description:** Potential enhancements and features for future development.

**Ideas:**
*   **Community Features:** Public sharing of stories with moderation, commenting, and liking.
*   **Advanced Customization:** More granular control over AI generation (e.g., character traits, specific plot points).
*   **Multi-language Support:** Expand language options for text and audio generation.
*   **User-Provided Assets:** Allow users to upload their own images or audio to influence the story.
*   **Subscription Tiers:** Differentiate features and usage limits for various subscription levels.
*   **Mobile Applications:** Native iOS/Android apps for enhanced performance and offline capabilities.

## 6. Open Questions & Assumptions

### Open Questions:
*   Specific budget for AI API calls (DALL-E, ElevenLabs, Pollo AI).
*   Exact performance requirements for background generation (e.g., maximum acceptable latency).
*   Detailed design for the "Continue Story" UI/UX flow.
*   Specific FFmpeg (or alternative) setup and capabilities on Lovable.dev servers.

### Assumptions:
*   Lovable.dev provides a robust environment for hosting Supabase Edge Functions and integrating external APIs.
*   Server-side access to FFmpeg or an equivalent video processing library is available.
*   Supabase storage is suitable for handling the volume of generated images and audio files.
*   The provided API keys for OpenAI, ElevenLabs, and Pollo AI will remain valid and have sufficient quotas.

## 7. Appendix

### 7.1 Glossary

*   **AI:** Artificial Intelligence
*   **DALL-E:** OpenAI's text-to-image generation model
*   **ElevenLabs:** Text-to-Speech (TTS) service
*   **FFmpeg:** Open-source multimedia framework for processing video and audio
*   **Gemini:** Google's multimodal AI model
*   **GPT-4o:** OpenAI's latest flagship model
*   **Pollo AI:** Image-to-video animation service
*   **PRD:** Product Requirements Document
*   **Supabase:** Open-source Firebase alternative (backend-as-a-service)
*   **TTS:** Text-to-Speech
*   **UI:** User Interface
*   **UX:** User Experience

### 7.2 References

*   Tale Forge 2 Application
*   Provided Application Documentation (pasted_content.txt)
*   OpenAI DALL-E API Documentation
*   ElevenLabs API Documentation
*   Pollo AI API Documentation
*   Supabase Documentation





## 8. Changelog Implementation Guide

To effectively communicate updates, new features, and bug fixes to your users and stakeholders, implementing a changelog is crucial. Here are different approaches and best practices for integrating a changelog into your TaleForge application.

### 8.1 Why a Changelog is Important

*   **Transparency:** Keeps users informed about what's new, what's changed, and what's been fixed.
*   **User Engagement:** Encourages users to explore new features and understand ongoing development.
*   **Trust and Credibility:** Demonstrates active development and responsiveness to feedback.
*   **Marketing Tool:** Highlights product evolution and value proposition.
*   **Internal Communication:** Serves as a historical record of development for the team.

### 8.2 Changelog Content Best Practices

*   **Categorize Changes:** Group changes into clear categories such as:
    *   `Added`: For new features.
    *   `Changed`: For changes in existing functionality.
    *   `Fixed`: For bug fixes.
    *   `Removed`: For deprecated or removed features.
    *   `Improved`: For performance enhancements or minor tweaks.
*   **Use Clear and Concise Language:** Avoid overly technical jargon. Explain changes in a way that is understandable to your target audience.
*   **Date and Version:** Each entry should be clearly dated and associated with a specific version number of the application.
*   **Reverse Chronological Order:** List the most recent changes first.
*   **Link to Relevant Resources:** If applicable, link to documentation, support articles, or blog posts for more details on a particular change.

### 8.3 Changelog Implementation Approaches

There are several ways to implement a changelog, ranging from simple static files to more dynamic, integrated solutions.

#### Approach 1: Static Markdown File (Simplest)

This is the easiest to implement and manage, especially for smaller projects or early stages.

*   **Implementation:** Create a `CHANGELOG.md` file in your project's root directory. Update this file manually with each new release.
*   **Display in App:** You can display this content directly in your application by fetching the raw Markdown file and rendering it. For a React app, you might fetch the `.md` file and use a Markdown renderer library.
*   **Pros:** Easy to set up, version-controlled with your code, human-readable.
*   **Cons:** Requires manual updates, no built-in search or filtering, might require a separate deployment step if not bundled with the app.

    **Example `CHANGELOG.md` structure:**
    ```markdown
    # Changelog

    ## [Unreleased]

    ## [1.0.1] - 2025-06-27

    ### Added
    - Implemented waitlist functionality on the landing page.
    - Added responsive design for various screen sizes.

    ### Fixed
    - Resolved login issues on TaleForge v3.
    - Corrected text overflow on smaller viewports.

    ### Changed
    - Updated genre selection UI for better user experience.

    ## [1.0.0] - 2025-06-20

    ### Added
    - Initial release of TaleForge application.
    - Core interactive storytelling with Gemini integration.
    - DALL-E 3 image generation.
    - ElevenLabs voice generation.
    ```

#### Approach 2: Dedicated Changelog Page/Component

This approach offers a more integrated and user-friendly experience within the application.

*   **Implementation:** Create a dedicated page or component within your application (e.g., `/changelog` route). This page would fetch changelog data from a structured source.
*   **Data Source Options:**
    *   **JSON File:** Store changelog entries in a `changelog.json` file. This allows for easier parsing and rendering in your frontend.
    *   **Database Table:** For more complex needs, store changelog entries in a database table (e.g., `changelog_entries`) with fields like `version`, `date`, `category`, `description`.
*   **Pros:** Better user experience, can implement search/filter functionality, more dynamic.
*   **Cons:** More complex to set up than a static Markdown file.

    **Example `changelog.json` structure:**
    ```json
    [
      {
        "version": "1.0.1",
        "date": "2025-06-27",
        "changes": [
          {
            "type": "Added",
            "description": "Implemented waitlist functionality on the landing page."
          },
          {
            "type": "Added",
            "description": "Added responsive design for various screen sizes."
          },
          {
            "type": "Fixed",
            "description": "Resolved login issues on TaleForge v3."
          },
          {
            "type": "Fixed",
            "description": "Corrected text overflow on smaller viewports."
          }
        ]
      },
      {
        "version": "1.0.0",
        "date": "2025-06-20",
        "changes": [
          {
            "type": "Added",
            "description": "Initial release of TaleForge application."
          },
          {
            "type": "Added",
            "description": "Core interactive storytelling with Gemini integration."
          }
        ]
      }
    ]
    ```

#### Approach 3: External Changelog Service (Advanced)

For larger projects or those requiring advanced features like subscriber notifications, consider using a dedicated changelog service.

*   **Examples:** Headway, Beamer, ReleaseNotes.io.
*   **Pros:** Professional appearance, built-in notification features, analytics, less development overhead.
*   **Cons:** Can be costly, adds an external dependency.

### 8.4 Recommendation for TaleForge

Given the current stage of TaleForge and the need for quick implementation for the competition, I recommend starting with **Approach 1: Static Markdown File (`CHANGELOG.md`)**. This is the fastest way to get a changelog up and running. Once the competition is over and the core features are stable, you can consider upgrading to Approach 2 for a more integrated experience.

**Steps to Implement `CHANGELOG.md`:**

1.  Create a file named `CHANGELOG.md` in the root directory of your TaleForge project.
2.  Populate it with the example structure provided above, updating the versions, dates, and descriptions to reflect your actual changes.
3.  In your React application, create a new component (e.g., `ChangelogPage.tsx`).
4.  Inside `ChangelogPage.tsx`, use `fetch` to retrieve the `CHANGELOG.md` file from your public directory.
5.  Use a Markdown rendering library (e.g., `react-markdown`) to display the content of the `CHANGELOG.md` file.
6.  Add a link to this `ChangelogPage` in your application's navigation (e.g., in the footer or a dedicated 

